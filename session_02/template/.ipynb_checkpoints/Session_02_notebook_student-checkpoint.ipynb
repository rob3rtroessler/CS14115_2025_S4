{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #FF7B47; padding: 10px; border: thin solid darblue; border-radius: 5px; margin-bottom: 2vh'>\n",
    "    \n",
    "# Session 02 - Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #FF7B47; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "    \n",
    "## Part 1 -  Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "A.1 - RegEx: Finding patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "A.2 - RegEx: Replacing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "B.1 - Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "B.2 - beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #6A9EB4; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "## Part 2 - Lab\n",
    "    \n",
    "During today's lab you will write code that will help the marketing manager of Harvard Athletics to find out which sports are underrepresented in Harvardâ€™s own newspaper, The Harvard Crimson, and need more publicity. You can find the sports features section here: https://www.thecrimson.com/tag/sports-features/page/1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #ADCAD6; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "## Task #1 - Finding the relevant information\n",
    "The marketing manager is especially interested in data from the years 2019-2021.  Begin with importing the relevant packages, scraping the first webpage. Don't forget to check if your fetch request was succesful. Next, parse the webpage using Beautiful Soup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful regex patter example:\n",
    "\n",
    "# Define the regex pattern for extracting the date in the URL\n",
    "sample_sub_string = r\"/(\\d{2})/(\\d{1,2})/\"\n",
    "\n",
    "#   /: Matches the literal \"/\" character\n",
    "#   (\\d{2}): Matches exactly four digits and captures them in a group\n",
    "#   /: Matches the literal \"/\" character\n",
    "#   (\\d{1,2}): Matches one or two digits and captures them in a group\n",
    "#   /: Matches the literal \"/\" character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #ADCAD6; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "Now onto the tricky part. To prepare a spreadsheet and eventually some plots for the marketing manager, we are interested in three things: the article tag, which will tell us what sport the article is dealing with, the article headline, and the year of publication. Let's begin with storing the  html elements that contain the article previews in a list. The Prettify() function as well as your developer tools in your browser will help you figure our what to look for. Once you've created your list, loop through your list to explore the elements further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #ADCAD6; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "Now that we have a list of all the article previews, we can finally extract the information we want. Using the developer tools in your browser, find a way to extract: \n",
    "    <li> the article title, \n",
    "    <li> the tag (e.g. \"Women's Rugby\", \"Football\", etc.), \n",
    "    <li> the number of authors\n",
    "    <li> the names of the authors as a list\n",
    "    <li> the date of the publication \n",
    "\n",
    "To get started, do this with one element in your article preview list. Hint 1: The year of publication is a little tricky to retrieve. RegEx might be able to help you here. Hint 2: Beautiful Soup functions returns Beautiful Soup objects. RegEx, however, only works on strings, so don't forget to turn your object into a string first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #ADCAD6; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "## Task #2 - generate a file with information for the marketing manager\n",
    "\n",
    "OK, now that you know how to retrieve this information, write a program that extracts this information and writes it into the csv file \"article_previews.csv\". If you can't quite remember how you create and write into files, take a look at yesterday's assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #CBE0A4; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "## Bonus Tasks\n",
    "Congratulations! You have created a csv file, which we can use to explore our extracted data. So far, the file, however, only features the most recent articles, i.e. the articles from page 1 of the Sport's Features section. Write a program that creates a csv file with tag, title, and year of all articles from 2021-2019. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
